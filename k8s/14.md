# Kube Prometheus Stack

## Table of Contents

- [Components description](#components-description)
- [Chart installation](#chart-installation)
- [`kubectl get` a lot of things](#kubectl-get-a-lot-of-things)
- [Grafana dashboards](#grafana-dashboards)
- [Init containers](#init-containers) (bonus, 3 init containers)
- [Adding the app metrics to the Prometheus](#adding-the-app-metrics-to-the-prometheus) (bonus)

## Components description

- **Prometheus Operator** — helper for easy Prometheus deployment and configuration in k8s
- **Prometheus** — metric database and visualization UI
- **Alertmanager** — utility to collect and route alerts from apps
- **Node exporter** — hardware metric fetcher for UNIX OSes
- **Prometheus Adapter for Kubernetes Metrics APIs** — adapter that implements k8s metrics APIs
- **kube-state-metrics** — service creating metrics from objects state fetched from k8s API
- **Grafana** — Dashboard engine that works with Prometheus and allows to visualize lots of data simultaneously

## Chart installation

I omitted the repo add/update command, here are the ones to install the charts:

```sh
helm install prometheus prometheus-community/kube-prometheus-stack
helm secrets -f ./secrets.yaml install py-app ./python-app/
```

## `kubectl get` a lot of things

Output of `kubectl get po,sts,svc,pvc,cm` is quite long. It shows Pods, StatefulSets, Services, PersistentVolumeClaims, and ConfigMaps in the default namespace.

<!-- markdownlint-disable MD033 -->
<details>
<summary>Show the output</summary>

```text
NAME                                                         READY   STATUS    RESTARTS   AGE
pod/alertmanager-prometheus-kube-prometheus-alertmanager-0   2/2     Running   0          36s
pod/prometheus-grafana-6fdd6868b4-6qsv7                      3/3     Running   0          39s
pod/prometheus-kube-prometheus-operator-6ffc69cf67-m95rn     1/1     Running   0          39s
pod/prometheus-kube-state-metrics-6cfd96f4c8-4t7jg           1/1     Running   0          39s
pod/prometheus-prometheus-kube-prometheus-prometheus-0       2/2     Running   0          34s
pod/prometheus-prometheus-node-exporter-nsq7m                1/1     Running   0          39s
pod/py-app-python-app-0                                      0/1     Running   0          17s
pod/py-app-python-app-1                                      0/1     Running   0          17s
pod/py-app-redis-7568c9bf5c-vhxbl                            1/1     Running   0          17s

NAME                                                                    READY   AGE
statefulset.apps/alertmanager-prometheus-kube-prometheus-alertmanager   1/1     37s
statefulset.apps/prometheus-prometheus-kube-prometheus-prometheus       1/1     35s
statefulset.apps/py-app-python-app                                      0/2     18s

NAME                                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
service/alertmanager-operated                     ClusterIP   None             <none>        9093/TCP,9094/TCP,9094/UDP   37s
service/kubernetes                                ClusterIP   10.96.0.1        <none>        443/TCP                      34d
service/prometheus-grafana                        ClusterIP   10.109.73.176    <none>        80/TCP                       40s
service/prometheus-kube-prometheus-alertmanager   ClusterIP   10.102.18.88     <none>        9093/TCP                     40s
service/prometheus-kube-prometheus-operator       ClusterIP   10.99.77.83      <none>        443/TCP                      40s
service/prometheus-kube-prometheus-prometheus     ClusterIP   10.98.207.113    <none>        9090/TCP                     40s
service/prometheus-kube-state-metrics             ClusterIP   10.99.182.58     <none>        8080/TCP                     40s
service/prometheus-operated                       ClusterIP   None             <none>        9090/TCP                     36s
service/prometheus-prometheus-node-exporter       ClusterIP   10.101.130.130   <none>        9100/TCP                     40s
service/py-app-python-app                         ClusterIP   10.110.57.86     <none>        8000/TCP                     18s
service/py-app-redis                              ClusterIP   10.99.178.91     <none>        6379/TCP                     18s

NAME                                                                     DATA   AGE
configmap/kube-root-ca.crt                                               1      34d
configmap/prometheus-grafana                                             1      40s
configmap/prometheus-grafana-config-dashboards                           1      40s
configmap/prometheus-kube-prometheus-alertmanager-overview               1      40s
configmap/prometheus-kube-prometheus-apiserver                           1      40s
configmap/prometheus-kube-prometheus-cluster-total                       1      40s
configmap/prometheus-kube-prometheus-controller-manager                  1      40s
configmap/prometheus-kube-prometheus-etcd                                1      40s
configmap/prometheus-kube-prometheus-grafana-datasource                  1      40s
configmap/prometheus-kube-prometheus-grafana-overview                    1      40s
configmap/prometheus-kube-prometheus-k8s-coredns                         1      40s
configmap/prometheus-kube-prometheus-k8s-resources-cluster               1      40s
configmap/prometheus-kube-prometheus-k8s-resources-namespace             1      40s
configmap/prometheus-kube-prometheus-k8s-resources-node                  1      40s
configmap/prometheus-kube-prometheus-k8s-resources-pod                   1      40s
configmap/prometheus-kube-prometheus-k8s-resources-workload              1      40s
configmap/prometheus-kube-prometheus-k8s-resources-workloads-namespace   1      40s
configmap/prometheus-kube-prometheus-kubelet                             1      40s
configmap/prometheus-kube-prometheus-namespace-by-pod                    1      40s
configmap/prometheus-kube-prometheus-namespace-by-workload               1      40s
configmap/prometheus-kube-prometheus-node-cluster-rsrc-use               1      40s
configmap/prometheus-kube-prometheus-node-rsrc-use                       1      40s
configmap/prometheus-kube-prometheus-nodes                               1      40s
configmap/prometheus-kube-prometheus-nodes-darwin                        1      40s
configmap/prometheus-kube-prometheus-persistentvolumesusage              1      40s
configmap/prometheus-kube-prometheus-pod-total                           1      40s
configmap/prometheus-kube-prometheus-prometheus                          1      40s
configmap/prometheus-kube-prometheus-proxy                               1      40s
configmap/prometheus-kube-prometheus-scheduler                           1      40s
configmap/prometheus-kube-prometheus-workload-total                      1      40s
configmap/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0   29     36s
configmap/redis-config                                                   1      18s
```

</details>

## Grafana dashboards

In my case the command to run the service is `minikube service prometheus-grafana` (since `RELEASE_NAME` for me is `prometheus`).

The default login credentials can be found from `<RELEASE_NAME>_grafana` secret, which has them base64-encoded.

Here is a shortcut to decode values with the use of `jq`:

```sh
kubectl get secret prometheus-grafana -o jsonpath="{.data}" | \
jq 'map_values(.|@base64d)'
```

```text
{
  "admin-password": "prom-operator",
  "admin-user": "admin",
  "ldap-toml": ""
}
```

### CPU and memory usage of the StatefulSet of the app

No data for usage for some reason. At least the quotas are shown.

![CPU](https://user-images.githubusercontent.com/29694249/205436844-ed9a7e10-9787-4162-b04a-e3953cff4da2.png)
![Memory](https://user-images.githubusercontent.com/29694249/205436852-05008fb8-cbdc-4838-9e9b-4ad6ccd781fd.png)

### Most CPU-using Pod in the default namespace

Well, also no usage here. But the quota on app pods is higher than on the Prometheus and Alertmanager.

![image](https://user-images.githubusercontent.com/29694249/205436948-591346a8-6e72-47fc-a862-4370aa5466c9.png)

### Node memory consumption and CPU usage

No memory info for the node and only the quotas in k8s `Compute Resources`.

![node](https://user-images.githubusercontent.com/29694249/205437221-e2bcdb52-24db-4e28-a48e-5c3b2f421d59.png)

However, `Node Exporter` dashboard shows all the necessary hardware stats:

![node-exporter](https://user-images.githubusercontent.com/29694249/205438164-cb2a5eb0-5aef-4d8a-ad6d-a70db27aebc9.png)

### Kubelet Pods and containers count

![image](https://user-images.githubusercontent.com/29694249/205437377-adcb5b33-cacb-4974-943b-b7ab51e517cb.png)

### Most network-using Pod in the default namespace

The data is missing in both k8s `Compute Resources` and `Networking` dashboards. I don't get why.

![image](https://user-images.githubusercontent.com/29694249/205437451-616a22c7-aaf4-48b9-8c79-966740e6bfe5.png)

![image](https://user-images.githubusercontent.com/29694249/205437940-5d788cc4-32d6-468f-acda-c14d8fd0fd0b.png)

### Alert count

![image](https://user-images.githubusercontent.com/29694249/205438318-5e8119db-40ad-453d-88fb-19ea6a4c64a5.png)

## Init containers

### Add volumes

First, we need to add a new volume:

```diff
  volumes:
+   - name: init-dir
+     emptyDir:
    - name: redis-config
      configMap:
        name: redis-config
```

Second, mount it to the app container:

```diff
  volumeMounts:
+   - name: init-dir
+     mountPath: "/init-dir"
+     readOnly: true
    - name: redis-config
      mountPath: "/config"
      readOnly: true
```

### Containers

I [added 3 init containers](./helm/python-app/templates/statefulset.yaml) that do the following:

- `wget -O /init-dir/info.json ifconfig.co/json` (download json with IP info)
- `awk '/time_zone/{ gsub(/[,"]/, "", $2); print $2 }' /init-dir/info.json > /init-dir/timezone` (find the timezone in the file and save it to a new file)
- `rm /init-dir/info.json` (remove the original file)

### Test

List files and print `timezone` file:

```sh
kubectl exec pod/py-app-python-app-0 -- \
  sh -c 'ls -l /init-dir && cat /init-dir/timezone'
```

```text
Defaulted container "python-app" out of: python-app, fetch-ipinfo (init), find-timezone (init), delete-ipinfo (init)
total 4
-rw-r--r--    1 root     root            17 Dec  3 12:04 timezone
Europe/Ulyanovsk
```

## Adding the app metrics to the Prometheus

Based on [this StackOverflow answer](https://stackoverflow.com/a/64507135), I added [prometheus YAML config](./helm/prometheus-py-app.yaml).

I had to change a label name there to prevent Prometheus from dropping the target:

```diff
- - source_labels: [__meta_kubernetes_pod_label_app]
+ - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
    action: keep
    regex: python-app
```

After reinstalling the chart with `helm install -f ./prometheus-py-app.yaml prometheus prometheus-community/kube-prometheus-stack` and opening Grafana, metrics from our app are observed in the Query Explorer:

![grafana](https://user-images.githubusercontent.com/29694249/205441892-a06b0816-a564-45e0-8586-d6f0ae3b8cbc.png)

The values look strange, because the python app restarted multiple times:

![kubectl get pods](https://user-images.githubusercontent.com/29694249/205441955-f3bce6be-dede-499c-bf5d-29249b2ca642.png)

The reason for restarts is the lack of RAM on my PC, it seems. Everything is quite laggy when the prometheus stack chart is installed, so I doubt I can do more beautiful screenshots.

![Memory](https://user-images.githubusercontent.com/29694249/205441875-64e2c60d-d345-4475-8822-04e98908ab52.png)
